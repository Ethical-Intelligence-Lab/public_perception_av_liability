# (1.1) BLAME HUMAN --------------------------------------------------
blame_man_mod <- lm(blame_man ~ person_cond*intention_cond, data=data)
summary(blame_man_mod)
tapply(data$blame_man, data$person_cond, mean)
tapply(data$blame_man, data$person_cond, sd)
var.test(data$blame_man[data$person_cond == 'pedestri'],
data$blame_man[data$person_cond == 'driver'])
blame_man_t <- t.test(data$blame_man[data$person_cond == 'pedestri'],
data$blame_man[data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
blame_man_t
# (1.2) BLAME AV -----------------------------------------------------
blame_av_mod <- lm(blame_av ~ person_cond*intention_cond, data=data)
summary(blame_av_mod)
var.test(data$blame_av[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_av[data$intention_cond == 'random' & data$person_cond == 'driver'])
blame_av_t <- t.test(data$blame_av[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_av[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
blame_av_t
# (1.3) BLAME FIRM ----------------------------------------------------
blame_company_mod <- lm(blame_company ~ person_cond*intention_cond, data=data)
summary(blame_company_mod)
var.test(data$blame_company[data$person_cond == 'pedestri'],
data$blame_company[data$person_cond == 'driver'])
blame_firm_t <- t.test(data$blame_company[data$person_cond == 'pedestri'],
data$blame_company[data$person_cond == 'driver'],
var.equal=FALSE, paired=FALSE)
blame_firm_t
tapply(data$blame_company, data$person_cond, mean)
tapply(data$blame_company, data$person_cond, sd)
# intentional pedestrian v. random driver
var.test(data$blame_company[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_company[data$intention_cond == 'random' & data$person_cond == 'driver'])
blame_company_t <- t.test(data$blame_company[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$blame_company[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=FALSE, paired=FALSE)
blame_company_t
## (2) OUTRAGE COMPANY -------------------------------------------
outrage_mod <- lm(outrage ~ person_cond*intention_cond, data=data)
summary(outrage_mod)
# driver v pedestrian, intentional
var.test(data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'driver'],
data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'])
outrage_1_t <- t.test(data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'driver'],
data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
var.equal=TRUE, paired=FALSE)
outrage_1_t
var.test(data$outrage[data$intention_cond == 'random' & data$person_cond == 'driver'],
data$outrage[data$intention_cond == 'random' & data$person_cond == 'pedestri'])
outrage_2_t <- t.test(data$outrage[data$intention_cond == 'random' & data$person_cond == 'driver'],
data$outrage[data$intention_cond == 'random' & data$person_cond == 'pedestri'],
var.equal=TRUE, paired=FALSE)
outrage_2_t
# intentional pedestrian v. random driver
var.test(data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$outrage[data$intention_cond == 'random' & data$person_cond == 'driver'])
outrage_company_t <- t.test(data$outrage[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$outrage[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
outrage_company_t
## (3) COLLECTIVE ACTION COMPANY ---------------------------------
col_action_mod <- lm(col_action ~ person_cond*intention_cond, data=data)
summary(col_action_mod)
# intentional pedestrian v. random driver
var.test(data$col_action[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$col_action[data$intention_cond == 'random' & data$person_cond == 'driver'])
ca_company_t <- t.test(data$col_action[data$intention_cond == 'intentional' & data$person_cond == 'pedestri'],
data$col_action[data$intention_cond == 'random' & data$person_cond == 'driver'],
var.equal=TRUE, paired=FALSE)
ca_company_t
##=============================================================================================================
##MEDIATION ANALYSIS##
##================================================================================================================
process(data = data, y = "blame_company", x = "intention_cond_num",
m =c("outrage"), model = 4, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
data$person_cond_num
process(data = data, y = "blame_company", x = "person_cond_num",
m =c("outrage"), w = "intention_cond_num", model = 83, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
process(data = data, y = "blame_company", x = "person_cond_num",
m =c("outrage"), w = "intention_cond_num", model = 7, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
## clear workspace
rm(list = ls())
source("process.R")
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools'        # get Cramer's V
)
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
# if importing from Qualtrics: (i) export data as numeric values, and (ii) delete rows 2 and 3 of the .csv file.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d <- read.csv('p1_e2_data.csv')
## explore dataframe:
dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d) # will provide all column names
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
## split up dataframes between AV and HDV conditions
## this is necessary before comprehension exclusions
d_AV <- subset(d, (d$FL_4_DO == "FL_39"))
d_HDV <- subset(d, (d$FL_4_DO == "FL_40"))
## get number of participants BEFORE exclusions:
n_original <- dim(d)[1] # extracting number of rows only, not columns
n_original_AV <- dim(d_AV)[1]
n_original_HDV <- dim(d_HDV)[1]
## perform comprehension exclusions separately for AV and HDV:
# this will remove responses from the dataframe that failed comprehension checks (i.e., "2")
d_AV <- subset(d_AV, (d_AV$comp1 == 1 & d_AV$comp_accident == 1))
d_HDV <- subset(d_HDV, (d_HDV$comp1 == "" & d_HDV$comp_accident == 1))
dim(d_AV) # number of participants should decrease after comprehension exclusions
dim(d_HDV)
## get number of participants AFTER exclusions:
n_final_AV <- dim(d_AV)[1] # extracting number of rows only, not columns
n_final_HDV <- dim(d_HDV)[1]
n_final <- n_final_AV + n_final_HDV
percent_excluded <- (n_original - n_final)/n_original
percent_excluded_AV <- (n_original_AV - n_final_AV)/n_original_AV
percent_excluded_HDV <- (n_original_HDV - n_final_HDV)/n_original_HDV
## remove unused columns according to condition
d_AV <- d_AV[-c(21:28,36:50)]
d_HDV <- d_HDV[-c(21:35,36:43)]
## get mean age and gender:
mean_age = mean(as.numeric(d$age), na.rm = TRUE) # removing NAs from the dataframe before computing mean
gender = table(d$gender)[1]/sum(table(d$gender))
## ================================================================================================================
##                                                    SUBSETTING
## ================================================================================================================
## define new data frame to extract pre-processed data into:
d_subset <- array(dim=c(n_final, 13))
colnames(d_subset) <- c('cond', 'vA_sue', 'vB_sue', 'defective', 'negligence', 'counterfactual',
'capability', 'fault', 'superhuman', 'comp1', 'comp2', 'familiarity', 'mod')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## assess moderator data from both AV and HDV
moderator_mat = rbind(d_AV[31:35], d_HDV[31:35])
moderator_mat$av_trust_5_1 = 100 - as.numeric(moderator_mat$av_trust_5_1)
moderator_mat <- data.frame(sapply(moderator_mat, as.numeric))
cb_alpha = cronbach.alpha(moderator_mat)
#d_AV$moderator <- rowMeans(sapply(d_AV[31:35], as.numeric))
#d_HDV$moderator <- rowMeans(d_HDV[31:35])
moderator_mat$moderator <- rowMeans(moderator_mat)
## extract good data from the middle part of raw data in AV:
for(i in 1:n_final_AV) {
curr <- d_AV[i,21:31][!is.na(d_AV[i,21:31])] # for a given row, get only the non-NA values
d_subset[i,2:12] <- as.numeric(curr[curr!= ""]) # and only the non-empty values
d_subset[i,13] <- moderator_mat$moderator[i]
d_subset[i,1] <- d_AV[i,43][!is.na(d_AV[i,43])]
}
## extract good data from the middle part of raw data in HDV:
for(i in 1:n_final_HDV) {
j = i+n_final_AV
curr <- d_HDV[i,21:31][!is.na(d_HDV[i,21:31])] # for a given row, get only the non-NA values
d_subset[j,2:12] <- as.numeric(curr) # and only the non-empty values
d_subset[j,13] <- moderator_mat$moderator[j]
d_subset[j,1] <- d_HDV[i,43][!is.na(d_HDV[i,43])]
}
## just to keep the df names straight for next section
d_merged <- d_subset
names(d_merged)[names(d_merged) == 'defective'] <- 'defec'
names(d_merged)[names(d_merged) == 'negligence'] <- 'negl'
names(d_merged)[names(d_merged) == 'counterfactual'] <- 'countf'
names(d_merged)[names(d_merged) == 'capability'] <- 'capab'
names(d_merged)[names(d_merged) == 'superhuman'] <- 'superh'
d_merged$countf2 <- d_merged$countf
d_merged$cond_name <- ifelse(d_merged$cond=="FL_39", "av", "human")
d_merged$cond_n <- ifelse(d_merged$cond_name=="av", 1, 2)
## ================================================================================================================
##                                             DATA ANALYSIS - T-TESTS
## ================================================================================================================
table(d_merged$con) #give us table of number of people in each condition - want to have equal number of people in each condition
## (1) SUE VEHICLE A DRIVER
vA_sue_T <- t.test(vA_sue ~ cond_name, data = d_merged, paired = FALSE)
print("VA_SUE:")
print(paste("statistic: ", vA_sue_T$statistic))
print(paste("p-value: ", vA_sue_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$vA_sue)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$vA_sue)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$vA_sue)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$vA_sue)))
print("")
## (2) SUE VEHICLE B MANUFACTURER
vB_sue_T <- t.test(vB_sue ~ cond_name, data = d_merged, paired = FALSE)
print("VB_SUE:")
print(paste("statistic: ", vB_sue_T$statistic))
print(paste("p-value: ", vB_sue_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$vB_sue)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$vB_sue)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$vB_sue)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$vB_sue)))
print("")
## (3) VEHICLE B DEFECTIVE
defective_T <- t.test(defec ~ cond_name, data = d_merged, paired = FALSE)
print("DEFECTIVE:")
print(paste("statistic: ", defective_T$statistic))
print(paste("p-value: ", defective_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$defec)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$defec)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$defec)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$defec)))
print("")
## (4) VEHICLE B NEGLIGENT
negligent_T <- t.test(negl ~ cond_name, data = d_merged, paired = FALSE)
print("NEGLIGENT:")
print(paste("statistic: ", negligent_T$statistic))
print(paste("p-value: ", negligent_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$negl)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$negl)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$negl)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$negl)))
print("")
## (5) COUNTERFACTUAL
counterfactual_T <- t.test(countf ~ cond_name, data = d_merged, paired = FALSE)
print("COUNTERFACTUAL:")
print(paste("statistic: ", counterfactual_T$statistic))
print(paste("p-value: ", counterfactual_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$countf)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$countf)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$countf)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$countf)))
print("")
## (6) CAPABILITY
capability_T <- t.test(capab ~ cond_name, data = d_merged, paired = FALSE)
print("CAPABILITY:")
print(paste("statistic: ", capability_T$statistic))
print(paste("p-value: ", capability_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$capab)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$capab)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$capab)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$capab)))
print("")
## (7) FAULT
fault_T <- t.test(fault ~ cond_name, data = d_merged, paired = FALSE)
print("FAULT:")
print(paste("statistic: ", fault_T$statistic))
print(paste("p-value: ", fault_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$fault)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$fault)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$fault)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$fault)))
print("")
## (8) SUPERHUMAN
superhuman_T <- t.test(superh ~ cond_name, data = d_merged, paired = FALSE)
print("SUPERHUMAN:")
print(paste("statistic: ", superhuman_T$statistic))
print(paste("p-value: ", superhuman_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$superh)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$superh)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$superh)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$superh)))
print("")
cor(d_merged[,2:9])
#
d_merged$trust_level <- ifelse(d_merged$mod>50, "High trust in AVs", "Low trust in AVs")
d_merged$trust_level_n <- ifelse(d_merged$trust_level=="High trust in AVs",2,1)
mod <- lm(countf ~ cond_name*superh, data = d_merged)
summary(mod)
mod_med <- median(d_merged$mod)
median(d_merged$mod)
d_merged$cond_name <- as.factor(d_merged$cond_name)
d_merged$trust_level <- as.factor(d_merged$trust_level)
mod <- aov(countf ~ trust_level*cond_name, data=d_merged)
summary(mod)
t.test(d_merged$countf[d_merged$cond_name=="av" & d_merged$trust_level_n == 1], d_merged$countf[d_merged$cond_name=="av" & d_merged$trust_level_n == 2], paired=FALSE)
t.test(d_merged$countf[d_merged$cond_name=="human" & d_merged$trust_level_n == 1], d_merged$countf[d_merged$cond_name=="human" & d_merged$trust_level_n == 2], paired=FALSE)
write.csv(d_merged, 'e2_processed.csv')
## ================================================================================================================
##                                             MEDIATION ANALYSIS
## ================================================================================================================
d_merged$cond_n <- ifelse(d_merged$cond=="FL_39", 1, 2)
# MODERATED SERIAL MEDIATION
# 87 = B path, 83 = A path, 91 = center path
process(data = d_merged, y = "vB_sue", x = "cond_n",
m =c("countf", "defec"), w = "mod", model = 83, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
source("process.R")
source("../process.R")
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools'        # get Cramer's V
)
## read in data:
# if importing from Qualtrics: (i) export data as numeric values, and (ii) delete rows 2 and 3 of the .csv file.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d <- read.csv('p1_e2_data.csv')
## explore dataframe:
dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d) # will provide all column names
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
## split up dataframes between AV and HDV conditions
## this is necessary before comprehension exclusions
d_AV <- subset(d, (d$FL_4_DO == "FL_39"))
d_HDV <- subset(d, (d$FL_4_DO == "FL_40"))
## get number of participants BEFORE exclusions:
n_original <- dim(d)[1] # extracting number of rows only, not columns
n_original_AV <- dim(d_AV)[1]
n_original_HDV <- dim(d_HDV)[1]
## perform comprehension exclusions separately for AV and HDV:
# this will remove responses from the dataframe that failed comprehension checks (i.e., "2")
d_AV <- subset(d_AV, (d_AV$comp1 == 1 & d_AV$comp_accident == 1))
d_HDV <- subset(d_HDV, (d_HDV$comp1 == "" & d_HDV$comp_accident == 1))
dim(d_AV) # number of participants should decrease after comprehension exclusions
dim(d_HDV)
## get number of participants AFTER exclusions:
n_final_AV <- dim(d_AV)[1] # extracting number of rows only, not columns
n_final_HDV <- dim(d_HDV)[1]
n_final <- n_final_AV + n_final_HDV
percent_excluded <- (n_original - n_final)/n_original
percent_excluded_AV <- (n_original_AV - n_final_AV)/n_original_AV
percent_excluded_HDV <- (n_original_HDV - n_final_HDV)/n_original_HDV
## remove unused columns according to condition
d_AV <- d_AV[-c(21:28,36:50)]
d_HDV <- d_HDV[-c(21:35,36:43)]
## get mean age and gender:
mean_age = mean(as.numeric(d$age), na.rm = TRUE) # removing NAs from the dataframe before computing mean
gender = table(d$gender)[1]/sum(table(d$gender))
## ================================================================================================================
##                                                    SUBSETTING
## ================================================================================================================
## define new data frame to extract pre-processed data into:
d_subset <- array(dim=c(n_final, 13))
colnames(d_subset) <- c('cond', 'vA_sue', 'vB_sue', 'defective', 'negligence', 'counterfactual',
'capability', 'fault', 'superhuman', 'comp1', 'comp2', 'familiarity', 'mod')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## assess moderator data from both AV and HDV
moderator_mat = rbind(d_AV[31:35], d_HDV[31:35])
moderator_mat$av_trust_5_1 = 100 - as.numeric(moderator_mat$av_trust_5_1)
moderator_mat <- data.frame(sapply(moderator_mat, as.numeric))
cb_alpha = cronbach.alpha(moderator_mat)
#d_AV$moderator <- rowMeans(sapply(d_AV[31:35], as.numeric))
#d_HDV$moderator <- rowMeans(d_HDV[31:35])
moderator_mat$moderator <- rowMeans(moderator_mat)
## extract good data from the middle part of raw data in AV:
for(i in 1:n_final_AV) {
curr <- d_AV[i,21:31][!is.na(d_AV[i,21:31])] # for a given row, get only the non-NA values
d_subset[i,2:12] <- as.numeric(curr[curr!= ""]) # and only the non-empty values
d_subset[i,13] <- moderator_mat$moderator[i]
d_subset[i,1] <- d_AV[i,43][!is.na(d_AV[i,43])]
}
## extract good data from the middle part of raw data in HDV:
for(i in 1:n_final_HDV) {
j = i+n_final_AV
curr <- d_HDV[i,21:31][!is.na(d_HDV[i,21:31])] # for a given row, get only the non-NA values
d_subset[j,2:12] <- as.numeric(curr) # and only the non-empty values
d_subset[j,13] <- moderator_mat$moderator[j]
d_subset[j,1] <- d_HDV[i,43][!is.na(d_HDV[i,43])]
}
## just to keep the df names straight for next section
d_merged <- d_subset
names(d_merged)[names(d_merged) == 'defective'] <- 'defec'
names(d_merged)[names(d_merged) == 'negligence'] <- 'negl'
names(d_merged)[names(d_merged) == 'counterfactual'] <- 'countf'
names(d_merged)[names(d_merged) == 'capability'] <- 'capab'
names(d_merged)[names(d_merged) == 'superhuman'] <- 'superh'
d_merged$countf2 <- d_merged$countf
d_merged$cond_name <- ifelse(d_merged$cond=="FL_39", "av", "human")
d_merged$cond_n <- ifelse(d_merged$cond_name=="av", 1, 2)
## ================================================================================================================
##                                             DATA ANALYSIS - T-TESTS
## ================================================================================================================
table(d_merged$con) #give us table of number of people in each condition - want to have equal number of people in each condition
## (1) SUE VEHICLE A DRIVER
vA_sue_T <- t.test(vA_sue ~ cond_name, data = d_merged, paired = FALSE)
print("VA_SUE:")
print(paste("statistic: ", vA_sue_T$statistic))
print(paste("p-value: ", vA_sue_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$vA_sue)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$vA_sue)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$vA_sue)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$vA_sue)))
print("")
## (2) SUE VEHICLE B MANUFACTURER
vB_sue_T <- t.test(vB_sue ~ cond_name, data = d_merged, paired = FALSE)
print("VB_SUE:")
print(paste("statistic: ", vB_sue_T$statistic))
print(paste("p-value: ", vB_sue_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$vB_sue)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$vB_sue)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$vB_sue)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$vB_sue)))
print("")
## (3) VEHICLE B DEFECTIVE
defective_T <- t.test(defec ~ cond_name, data = d_merged, paired = FALSE)
print("DEFECTIVE:")
print(paste("statistic: ", defective_T$statistic))
print(paste("p-value: ", defective_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$defec)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$defec)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$defec)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$defec)))
print("")
## (4) VEHICLE B NEGLIGENT
negligent_T <- t.test(negl ~ cond_name, data = d_merged, paired = FALSE)
print("NEGLIGENT:")
print(paste("statistic: ", negligent_T$statistic))
print(paste("p-value: ", negligent_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$negl)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$negl)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$negl)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$negl)))
print("")
## (5) COUNTERFACTUAL
counterfactual_T <- t.test(countf ~ cond_name, data = d_merged, paired = FALSE)
print("COUNTERFACTUAL:")
print(paste("statistic: ", counterfactual_T$statistic))
print(paste("p-value: ", counterfactual_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$countf)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$countf)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$countf)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$countf)))
print("")
## (6) CAPABILITY
capability_T <- t.test(capab ~ cond_name, data = d_merged, paired = FALSE)
print("CAPABILITY:")
print(paste("statistic: ", capability_T$statistic))
print(paste("p-value: ", capability_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$capab)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$capab)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$capab)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$capab)))
print("")
## (7) FAULT
fault_T <- t.test(fault ~ cond_name, data = d_merged, paired = FALSE)
print("FAULT:")
print(paste("statistic: ", fault_T$statistic))
print(paste("p-value: ", fault_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$fault)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$fault)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$fault)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$fault)))
print("")
## (8) SUPERHUMAN
superhuman_T <- t.test(superh ~ cond_name, data = d_merged, paired = FALSE)
print("SUPERHUMAN:")
print(paste("statistic: ", superhuman_T$statistic))
print(paste("p-value: ", superhuman_T$p.value))
print(paste("AV mean: ", mean(d_merged[d_merged$cond_name == "av",]$superh)))
print(paste("Human mean: ", mean(d_merged[d_merged$cond_name == "human",]$superh)))
print(paste("AV std: ", sd(d_merged[d_merged$cond_name == "av",]$superh)))
print(paste("Human std: ", sd(d_merged[d_merged$cond_name == "human",]$superh)))
print("")
cor(d_merged[,2:9])
#
d_merged$trust_level <- ifelse(d_merged$mod>50, "High trust in AVs", "Low trust in AVs")
d_merged$trust_level_n <- ifelse(d_merged$trust_level=="High trust in AVs",2,1)
mod <- lm(countf ~ cond_name*superh, data = d_merged)
summary(mod)
mod_med <- median(d_merged$mod)
median(d_merged$mod)
d_merged$cond_name <- as.factor(d_merged$cond_name)
d_merged$trust_level <- as.factor(d_merged$trust_level)
mod <- aov(countf ~ trust_level*cond_name, data=d_merged)
summary(mod)
t.test(d_merged$countf[d_merged$cond_name=="av" & d_merged$trust_level_n == 1], d_merged$countf[d_merged$cond_name=="av" & d_merged$trust_level_n == 2], paired=FALSE)
t.test(d_merged$countf[d_merged$cond_name=="human" & d_merged$trust_level_n == 1], d_merged$countf[d_merged$cond_name=="human" & d_merged$trust_level_n == 2], paired=FALSE)
write.csv(d_merged, 'e2_processed.csv')
## ================================================================================================================
##                                             MEDIATION ANALYSIS
## ================================================================================================================
d_merged$cond_n <- ifelse(d_merged$cond=="FL_39", 1, 2)
# MODERATED SERIAL MEDIATION
# 87 = B path, 83 = A path, 91 = center path
process(data = d_merged, y = "vB_sue", x = "cond_n",
m =c("countf", "defec"), w = "mod", model = 83, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
