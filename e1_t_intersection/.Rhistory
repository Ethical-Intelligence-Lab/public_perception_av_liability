curr_risk <- d_subset$risk[i]
d_plot[i,2] <- curr_fear
d_plot[i,1] <- "Familiarity"
d_plot[n_final+i, 2] <- curr_safety
d_plot[n_final+i,1] <- "Fear"
d_plot[2*n_final+i, 2] <- curr_familiarity
d_plot[2*n_final+i,1] <- "Risk"
d_plot[3*n_final+i, 2] <- curr_risk
d_plot[3*n_final+i,1] <- "Safety"
}
d_plot
## clear workspace
rm(list = ls())
# source("../process.R")
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc'
)
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
# if importing from Qualtrics: (i) export data as numeric values, and (ii) delete rows 2 and 3 of the .csv file.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d <- read.csv('pre_study.csv')
## explore dataframe:
dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d) # will provide all column names
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
n_final <- dim(d)[1]; n_final
## remove unused columns according to condition
d_cleaned <- d[c(21:24)]
## get mean age and gender:
mean_age = mean(as.numeric(d$age), na.rm = TRUE); mean_age # removing NAs from the dataframe before computing mean
gender = table(d$gender)[2]/sum(table(d$gender)); gender
## ================================================================================================================
##                                                    SUBSETTING
## ================================================================================================================
## define new data frame to extract pre-processed data into:
d_subset <- array(dim=c(n_final, 4))
colnames(d_subset) <- c('fear', 'safety', 'familiarity', 'risk')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## extract good data from the middle part of raw data in AV:
for(i in 1:n_final) {
curr <- d_cleaned[i,1:4][!is.na(d[i,1:4])] # for a given row, get only the non-NA values
d_subset[i,1:4] <- as.numeric(curr[curr!= ""]) # and only the non-empty values
}
## ================================================================================================================
##                                                  DATA ANALYSIS
## ================================================================================================================
### I am more afraid of riding in an autonomous vehicle
mean(d_subset$fear)
sd(d_subset$fear)
t_fear <- t.test(d_subset$fear, mu=50); t_fear
### I believe that HDVs are safer
mean(d_subset$safety)
sd(d_subset$safety)
t_safety <- t.test(d_subset$safety, mu=50); t_safety
### I am more familiar with HDVs
mean(d_subset$familiarity)
sd(d_subset$familiarity)
t_familiarity <- t.test(d_subset$familiarity, mu=50); t_familiarity
### It would be more risky to ride in an AV
mean(d_subset$risk)
sd(d_subset$risk)
t_risk <- t.test(d_subset$risk, mu=50); t_risk
## ================================================================================================================
##                                                    PLOTS
## ================================================================================================================
# Reshape data for plotting
d_plot <- array(dim=c(n_final*4, 2))
colnames(d_plot) <- c('question', 'measure')
d_plot <- as.data.frame(d_plot, stringsAsFactors=FALSE)
## extract good data from the middle part of raw data in AV:
for(i in 1:n_final) {
curr_fear <- d_subset$fear[i]#$fear[!is.na(d_subset)$fear] # for a given row, get only the non-NA values
curr_safety <- d_subset$safety[i]
curr_familiarity <- d_subset$familiarity[i]
curr_risk <- d_subset$risk[i]
d_plot[i,2] <- curr_fear
d_plot[i,1] <- "Familiarity"
d_plot[n_final+i, 2] <- curr_safety
d_plot[n_final+i,1] <- "Fear"
d_plot[2*n_final+i, 2] <- curr_familiarity
d_plot[2*n_final+i,1] <- "Risk"
d_plot[3*n_final+i, 2] <- curr_risk
d_plot[3*n_final+i,1] <- "Safety"
}
t_names <- c("Fear", "Safety", "Familiarity", "Risk")
## (1) Plot
p1_1 <- ggplot(d_plot,aes(x=factor(question),y=measure)) +
theme_bw() + coord_cartesian(ylim=c(1,110))+scale_y_continuous(breaks = scales::pretty_breaks(n = 3))+
geom_signif(y_position = c(105,105), comparisons = list(c(1, 1)), annotation="***", textsize = 6)+
geom_signif(y_position = c(105,105), comparisons = list(c(2, 2)), annotation="***", textsize = 6)+
geom_signif(y_position = c(105,105), comparisons = list(c(3, 3)), annotation="***", textsize = 6)+
geom_signif(y_position = c(105,105), comparisons = list(c(4, 4)), annotation="***", textsize = 6)+
coord_cartesian(ylim=c(1,125))
#geom_signif(y_position = c(119,116), comparisons = list(c(3, 4)), annotation="***", textsize = 6)+
p1_1 <- p1_1 + theme(text = element_text(size=20),panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
scale_x_discrete(labels=t_names) +
#ggtitle("Agreements with Statements") +
xlab ("Comparative Statement") + ylab ("Mean Agreement") +
theme_classic() +
theme(axis.text.x = element_text(size=15)) +
theme(axis.title = element_text(size=18)) +
theme(axis.text.y = element_text(size=14)) +
theme(plot.title = element_text(size=20, hjust=0.5)) +
geom_violin(width=0.9, alpha=0.38, size=0.75) +
geom_sina(alpha=0.6, size=0.95, color = "#999999") +
stat_summary(fun.data = "mean_cl_boot", color = "black",
size=0.4,
position = position_dodge(width = 0.9)) +
stat_summary(fun.data = "mean_cl_boot", color = "black",
position = position_dodge(width = 0.9),
geom="errorbar", width = 0.2)
p1_1 <- p1_1+geom_hline(yintercept=50,linetype=2, color="gray")
plot(p1_1)
dev.new(width=11,height=6,noRStudioGD = TRUE)
p1_1
## ================================================================================================================
##                                                  END OF ANALYSIS
## ================================================================================================================
## clear workspace
rm(list = ls())
source("../process.R")
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc'
)
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
# if importing from Qualtrics: (i) export data as numeric values, and (ii) delete rows 2 and 3 of the .csv file.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d <- read.csv('e1_data.csv')
## explore dataframe:
dim <- dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d) # will provide all column names
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
d$Finished
## split up dataframes between AV and HDV conditions
## this is necessary before comprehension exclusions
d_AV <- subset(d, (d$FL_4_DO == "FL_39"))
d_HDV <- subset(d, (d$FL_4_DO == "FL_40"))
## get number of participants BEFORE exclusions:
n_original <- dim(d)[1] # extracting number of rows only, not columns
## get number of participants BEFORE exclusions:
n_original <- dim(d)[1]; n_original # extracting number of rows only, not columns
dim(d_HDV)
## get number of participants AFTER exclusions:
n_final_AV <- dim(d_AV)[1] # extracting number of rows only, not columns
n_final_HDV <- dim(d_HDV)[1]
n_final <- n_final_AV + n_final_HDV
n_final <- n_final_AV + n_final_HDV; n_final
## clear workspace
rm(list = ls())
source("../process.R")
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc'
)
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
# if importing from Qualtrics: (i) export data as numeric values, and (ii) delete rows 2 and 3 of the .csv file.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d <- read.csv('e1_data.csv')
## explore dataframe:
dim <- dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d) # will provide all column names
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
## split up dataframes between AV and HDV conditions
## this is necessary before comprehension exclusions
d_AV <- subset(d, (d$FL_4_DO == "FL_39"))
d_HDV <- subset(d, (d$FL_4_DO == "FL_40"))
## get number of participants BEFORE exclusions:
n_original <- dim(d)[1]; n_original # extracting number of rows only, not columns
n_original_AV <- dim(d_AV)[1]
n_original_HDV <- dim(d_HDV)[1]
## perform comprehension exclusions separately for AV and HDV:
# this will remove responses from the dataframe that failed comprehension checks (i.e., "2")
d_AV <- subset(d_AV, (d_AV$comp1 == 1 & d_AV$comp_accident == 1))
d_HDV <- subset(d_HDV, (d_HDV$comp1 == "" & d_HDV$comp_accident == 1))
dim(d_AV) # number of participants should decrease after comprehension exclusions
dim(d_HDV)
## get number of participants AFTER exclusions:
n_final_AV <- dim(d_AV)[1] # extracting number of rows only, not columns
n_final_HDV <- dim(d_HDV)[1]
n_final <- n_final_AV + n_final_HDV; n_final
percent_excluded <- (n_original - n_final)/n_original
percent_excluded_AV <- (n_original_AV - n_final_AV)/n_original_AV
percent_excluded_HDV <- (n_original_HDV - n_final_HDV)/n_original_HDV
## remove unused columns according to condition
d_AV <- d_AV[-c(21:28,36:50)]
d_HDV <- d_HDV[-c(21:35,36:43)]
## get mean age and gender:
# mean(d$age, na.rm = TRUE) # removing NAs from the dataframe before computing mean
mean_age = mean(as.numeric(d$age), na.rm = TRUE)
## get mean age and gender:
# mean(d$age, na.rm = TRUE) # removing NAs from the dataframe before computing mean
mean_age = mean(as.numeric(d$age), na.rm = TRUE); mean_age
gender <- table(d$gender)[2]/sum(table(d$gender)); gender
## define new data frame to extract pre-processed data into:
d_subset <- array(dim=c(n_final, 12))
colnames(d_subset) <- c('cond', 'vA_sue', 'vB_sue', 'defective', 'negligence', 'counterfactual',
'capability', 'fault', 'superhuman', 'comp1', 'comp2', 'familiarity')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## clear workspace
rm(list = ls())
source("../process.R")
options(download.file.method="libcurl")
## install packages
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load('ggplot2',         # plotting
'ggsignif',        # plotting significance bars
'lme4',            # functions for fitting linear regression models
'ggforce',         # make ggplot even fancier
'ggpubr',          # arrange plots in a grid, if needed
'ltm',             # probably not using..
'tidyr',           # tools for cleaning messy data
'stringr',         # perform string substitutions easily
'assertthat',      # allows me to check whether a variable is a string, with is.string
'lsmeans',         # contrast analysis for regression models
'stats',           # use function to adjust for multiple comparisons
'filesstrings',    # create and move files
'simr',            # power analysis for mixed models
'compute.es',      # effect size package
'effsize',         # another effect size package
'pwr',             # package for power calculation
'nlme',            # get p values for mixed effect model
'DescTools',       # get Cramer's V
'Hmisc'
)
## ================================================================================================================
##                                                  PRE-PROCESSING
## ================================================================================================================
## read in data:
# if importing from Qualtrics: (i) export data as numeric values, and (ii) delete rows 2 and 3 of the .csv file.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to current directory
d <- read.csv('e1_data.csv')
## explore dataframe:
dim <- dim(d) # will provide dimensions of the dataframe by row [1] and column [2]
colnames(d) # will provide all column names
summary(d)
## perform attention exclusions:
# this will remove responses from the dataframe that failed attention checks (i.e., "1" or "2")
d <- subset(d, (d$att1 == 2 & d$att2 == 2))
dim(d) # number of participants should decrease after attention exclusions
## split up dataframes between AV and HDV conditions
## this is necessary before comprehension exclusions
d_AV <- subset(d, (d$FL_4_DO == "FL_39"))
d_HDV <- subset(d, (d$FL_4_DO == "FL_40"))
## get number of participants BEFORE exclusions:
n_original <- dim(d)[1]; n_original # extracting number of rows only, not columns
n_original_AV <- dim(d_AV)[1]
n_original_HDV <- dim(d_HDV)[1]
## perform comprehension exclusions separately for AV and HDV:
# this will remove responses from the dataframe that failed comprehension checks (i.e., "2")
d_AV <- subset(d_AV, (d_AV$comp1 == 1 & d_AV$comp_accident == 1))
d_HDV <- subset(d_HDV, (d_HDV$comp1 == "" & d_HDV$comp_accident == 1))
dim(d_AV) # number of participants should decrease after comprehension exclusions
dim(d_HDV)
## get number of participants AFTER exclusions:
n_final_AV <- dim(d_AV)[1] # extracting number of rows only, not columns
n_final_HDV <- dim(d_HDV)[1]
n_final <- n_final_AV + n_final_HDV; n_final
percent_excluded <- (n_original - n_final)/n_original
percent_excluded_AV <- (n_original_AV - n_final_AV)/n_original_AV
percent_excluded_HDV <- (n_original_HDV - n_final_HDV)/n_original_HDV
## remove unused columns according to condition
d_AV <- d_AV[-c(21:28,36:50)]
d_HDV <- d_HDV[-c(21:35,36:43)]
## get mean age and gender:
# mean(d$age, na.rm = TRUE) # removing NAs from the dataframe before computing mean
mean_age = mean(as.numeric(d$age), na.rm = TRUE); mean_age
gender <- table(d$gender)[2]/sum(table(d$gender)); gender
## ================================================================================================================
##                                                    SUBSETTING
## ================================================================================================================
## define new data frame to extract pre-processed data into:
d_subset <- array(dim=c(n_final, 12))
colnames(d_subset) <- c('cond', 'vA_sue', 'vB_sue', 'defective', 'negligence', 'counterfactual',
'capability', 'fault', 'superhuman', 'comp1', 'comp2', 'familiarity')
d_subset <- as.data.frame(d_subset, stringsAsFactors=FALSE)
## extract good data from the middle part of raw data in AV:
for(i in 1:n_final_AV) {
curr <- d_AV[i,21:31][!is.na(d_AV[i,21:31])] # for a given row, get only the non-NA values
d_subset[i,2:12] <- as.numeric(curr[curr!= ""]) # and only the non-empty values
d_subset[i,1] <- d_AV[i,37][!is.na(d_AV[i,37])]
}
## extract good data from the middle part of raw data in HDV:
for(i in 1:n_final_HDV) {
j = i+n_final_AV
curr <- d_HDV[i,21:31][!is.na(d_HDV[i,21:31])] # for a given row, get only the non-NA values
d_subset[j,2:12] <- as.numeric(curr) # and only the non-empty values
d_subset[j,1] <- d_HDV[i,37][!is.na(d_HDV[i,37])]
}
## keep the df names straight for next section
d_merged <- d_subset
names(d_merged)[names(d_merged) == 'defective'] <- 'defec'
names(d_merged)[names(d_merged) == 'negligence'] <- 'negl'
names(d_merged)[names(d_merged) == 'counterfactual'] <- 'countf'
names(d_merged)[names(d_merged) == 'capability'] <- 'capab'
names(d_merged)[names(d_merged) == 'superhuman'] <- 'superh'
d_merged$countf2 <- d_merged$countf
d_merged$cond_name <- ifelse(d_merged$cond=="FL_39", "av", "human")
d_merged$cond_n <- ifelse(d_merged$cond_name=="av", 1, 2)
## run t-tests to compare friendship, partnership, and willingness to pay measures between conditions:
table(d_merged$con) #give us table of number of people in each condition - want to have equal number of people in each condition
## run t-tests to compare friendship, partnership, and willingness to pay measures between conditions:
table(d_merged$con) #give us table of number of people in each condition - want to have equal number of people in each condition
## run t-tests to compare friendship, partnership, and willingness to pay measures between conditions:
table(d_merged$cond_n) #give us table of number of people in each condition - want to have equal number of people in each condition
## (1) SUE VEHICLE A DRIVER
vA_sue_T <- t.test(vA_sue ~ cond_name, data = d_merged, paired = FALSE)
vA_sue_T
## (1) SUE VEHICLE A DRIVER
vA_sue_T <- t.test(vA_sue ~ cond_name, data = d_merged, paired = FALSE); vA_sue_T
sd(d_merged[d_merged$cond_name == "av",]$vA_sue)
sd(d_merged[d_merged$cond_name == "human",]$vA_sue)
## (1) SUE VEHICLE A DRIVER
vA_sue_T <- t.test(vA_sue ~ cond_name, data = d_merged, paired = FALSE); vA_sue_T
## (2) SUE VEHICLE B MANUFACTURER
vB_sue_T <- t.test(vB_sue ~ cond_name, data = d_merged, paired = FALSE); vB_sue_T
## (2) SUE VEHICLE B MANUFACTURER
vB_sue_T <- t.test(vB_sue ~ cond_name, data = d_merged, paired = FALSE); vB_sue_T
sd(d_merged[d_merged$cond_name == "av",]$vB_sue)
sd(d_merged[d_merged$cond_name == "human",]$vB_sue)
## (2) SUE VEHICLE B MANUFACTURER
vB_sue_T <- t.test(vB_sue ~ cond_name, data = d_merged, paired = FALSE); vB_sue_T
## (3) VEHICLE B DEFECTIVE
defective_T <- t.test(defec ~ cond_name, data = d_merged, paired = FALSE); defective_T
## (3) VEHICLE B DEFECTIVE
defective_T <- t.test(defec ~ cond_name, data = d_merged, paired = FALSE); defective_T
sd(d_merged[d_merged$cond_name == "av",]$defec)
sd(d_merged[d_merged$cond_name == "human",]$defec)
## (4) VEHICLE B NEGLIGENT
negligent_T <- t.test(negl ~ cond_name, data = d_merged, paired = FALSE); negligent_T
sd(d_merged[d_merged$cond_name == "av",]$negl)
sd(d_merged[d_merged$cond_name == "human",]$negl)
## (5) COUNTERFACTUAL
counterfactual_T <- t.test(countf ~ cond_name, data = d_merged, paired = FALSE); counterfactual_T
## (4) VEHICLE B NEGLIGENT
negligent_T <- t.test(negl ~ cond_name, data = d_merged, paired = FALSE); negligent_T
## (4) VEHICLE B NEGLIGENT
negligent_T <- t.test(negl ~ cond_name, data = d_merged, paired = FALSE); negligent_T
sd(d_merged[d_merged$cond_name == "av",]$negl)
sd(d_merged[d_merged$cond_name == "human",]$negl)
## (6) FAULT or EXPECTATIONS
fault_T <- t.test(fault ~ cond_name, data = d_merged, paired = FALSE)
## (6) FAULT or EXPECTATIONS
fault_T <- t.test(fault ~ cond_name, data = d_merged, paired = FALSE); fault_T
sd(d_merged[d_merged$cond_name == "av",]$fault)
sd(d_merged[d_merged$cond_name == "human",]$fault)
## (7) CAPABILITY
capability_T <- t.test(capab ~ cond_name, data = d_merged, paired = FALSE); capability_T
sd(d_merged[d_merged$cond_name == "av",]$capab)
sd(d_merged[d_merged$cond_name == "human",]$capab)
## (7) COUNTERFACTUAL
counterfactual_T <- t.test(countf ~ cond_name, data = d_merged, paired = FALSE); counterfactual_T
sd(d_merged[d_merged$cond_name == "av",]$countf)
sd(d_merged[d_merged$cond_name == "human",]$countf)
## (8) SUPERHUMAN
superhuman_T <- t.test(superh ~ cond_name, data = d_merged, paired = FALSE); superhuman_T
## (8) SUPERHUMAN
superhuman_T <- t.test(superh ~ cond_name, data = d_merged, paired = FALSE); superhuman_T
sd(d_merged[d_merged$cond_name == "av",]$superh)
sd(d_merged[d_merged$cond_name == "human",]$superh)
cor(d_merged[,2:9])
mod <- lm(countf ~ cond_name*superh, data = d_merged)
summary(mod)
process(data = d_merged, y = "vB_sue", x = "cond_n",
m =c("countf", "capab", "defec", "fault", "negl"), model = 4, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
# SERIAL MEDIATION
process(data = d_merged, y = "vB_sue", x = "cond_n",
m =c("countf", "defec"), model = 6, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
process(data = d_merged, y = "vB_sue", x = "cond_n",
m =c("countf", "defec"), w = "superh", model = 83, effsize =1, total =1, stand =1,
contrast =1, boot = 10000 , modelbt = 1, seed = 654321)
d_merged$superh
d_merged$superhuman_level <- ifelse(d_merged$superh>50, "AVs should be superhuman", "AVs should not be superhuman")
d_merged$superhuman_level_n <- ifelse(d_merged$superh="AVs should be superhuman",2,1)
d_merged$superhuman_level_n <- ifelse(d_merged$superh=="AVs should be superhuman",2,1)
d_merged$superh_level <- ifelse(d_merged$superh>50, "AVs should be superhuman", "AVs should not be superhuman")
d_merged$superh_level_n <- ifelse(d_merged$superh=="AVs should be superhuman",2,1)
d_merged$superh_level <- as.factor(d_merged$trust_level)
#plot trust v. counterfactual relationship
dev.new(width=13,height=6,noRStudioGD = TRUE)
p1_0 <- ggplot(d_merged,aes(x=factor(cond_name),y=countf, fill=superh_level)) +
theme_bw() + coord_cartesian(ylim=c(1,110))+scale_y_continuous(breaks = scales::pretty_breaks(n = 3))+
geom_signif(y_position = 105.00, xmin = c(0.8,1.8), xmax = c(1.2,2.2), annotation = c("***","ns"), textsize=7.5)
p1_0 <- p1_0 + theme(text = element_text(size=16),panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
scale_x_discrete(labels=t_names) +
ggtitle("Agreement Wt. Counterfactual") +
xlab ("Vehicle Type") + ylab ("Mean Agreement") +
theme_classic() +
theme(axis.text.x = element_text(size=15)) +
theme(axis.text.y = element_text(size=15)) +
theme(axis.title = element_text(size=18)) +
theme(plot.title = element_text(size=18, hjust=0.5)) +
theme(legend.text=element_text(size=14),legend.title=element_text(size=14), legend.position="top")+
labs(fill='')+
geom_violin(width=0.9, alpha=0.38, size=0.75) +
geom_sina(alpha=0.6, size=0.95, color = "#999999") +
stat_summary(fun.data = "mean_cl_boot", color = "black",
size=0.4,
position = position_dodge(width = 0.9)) +
stat_summary(fun.data = "mean_cl_boot", color = "black",
position = position_dodge(width = 0.9),
geom="errorbar", width = 0.2)
p1_0
## plotting all measures
## FL39 --> AV condition; FL40 --> HDV condition
t_names <- c("AV", "HDV")
#plot trust v. counterfactual relationship
dev.new(width=13,height=6,noRStudioGD = TRUE)
p1_0 <- ggplot(d_merged,aes(x=factor(cond_name),y=countf, fill=superh_level)) +
theme_bw() + coord_cartesian(ylim=c(1,110))+scale_y_continuous(breaks = scales::pretty_breaks(n = 3))+
geom_signif(y_position = 105.00, xmin = c(0.8,1.8), xmax = c(1.2,2.2), annotation = c("***","ns"), textsize=7.5)
p1_0 <- p1_0 + theme(text = element_text(size=16),panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
scale_x_discrete(labels=t_names) +
ggtitle("Agreement Wt. Counterfactual") +
xlab ("Vehicle Type") + ylab ("Mean Agreement") +
theme_classic() +
theme(axis.text.x = element_text(size=15)) +
theme(axis.text.y = element_text(size=15)) +
theme(axis.title = element_text(size=18)) +
theme(plot.title = element_text(size=18, hjust=0.5)) +
theme(legend.text=element_text(size=14),legend.title=element_text(size=14), legend.position="top")+
labs(fill='')+
geom_violin(width=0.9, alpha=0.38, size=0.75) +
geom_sina(alpha=0.6, size=0.95, color = "#999999") +
stat_summary(fun.data = "mean_cl_boot", color = "black",
size=0.4,
position = position_dodge(width = 0.9)) +
stat_summary(fun.data = "mean_cl_boot", color = "black",
position = position_dodge(width = 0.9),
geom="errorbar", width = 0.2)
p1_0
